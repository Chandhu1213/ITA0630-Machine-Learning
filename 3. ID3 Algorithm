import pandas as pd
from math import log2

# Small dataset
data = {
    'Outlook': ['Sunny','Sunny','Overcast','Rain','Rain','Sunny','Overcast','Rain'],
    'Humidity': ['High','High','High','High','Normal','Normal','Normal','High'],
    'Play': ['No','No','Yes','Yes','Yes','Yes','Yes','No']
}

df = pd.DataFrame(data)

# Entropy
def entropy(col):
    counts = col.value_counts()
    total = len(col)
    return -sum((c/total)*log2(c/total) for c in counts)

# Information Gain
def info_gain(df, attr):
    total_entropy = entropy(df['Play'])
    values = df[attr].unique()
    weighted_entropy = 0
    for v in values:
        subset = df[df[attr] == v]
        weighted_entropy += (len(subset)/len(df)) * entropy(subset['Play'])
    return total_entropy - weighted_entropy

# ID3 (one-level tree for simplicity)
attributes = ['Outlook','Humidity']
gains = {attr: info_gain(df, attr) for attr in attributes}
best_attr = max(gains, key=gains.get)

print("Best Attribute (Root):", best_attr)

# Simple Tree Construction
tree = {best_attr: {}}
for value in df[best_attr].unique():
    subset = df[df[best_attr] == value]
    tree[best_attr][value] = subset['Play'].mode()[0]

print("Decision Tree:", tree)

# Classify new sample
sample = {'Outlook': 'Sunny', 'Humidity': 'High'}
prediction = tree[best_attr][sample[best_attr]]

print("New Sample:", sample)
print("Prediction:", prediction)
